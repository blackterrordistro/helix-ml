//! üåÄ HelixML Gradient Checkpointing Example
//! 
//! –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏.

use helix_ml::*;
use helix_ml::tensor::{TensorRandom, TensorOps};

fn main() -> Result<()> {
    println!("üåÄ HelixML Gradient Checkpointing Example");
    println!("==========================================");
    
    let device = Device::cpu();
    
    // 1. –°–æ–∑–¥–∞–µ–º autograd –∫–æ–Ω—Ç–µ–∫—Å—Ç
    let mut ctx = AutogradContext::<CpuTensor>::new();
    
    println!("\n1. Creating AutogradContext:");
    println!("  Initial checkpoint count: {}", ctx.checkpoint_count());
    
    // 2. –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã
    let input_data = CpuTensor::random_uniform(Shape::new(vec![2, 4]), -1.0, 1.0, &device)?;
    let input_id = ctx.tensor(input_data, true);
    
    let weight_data = CpuTensor::random_uniform(Shape::new(vec![3, 4]), -1.0, 1.0, &device)?;
    let weight_id = ctx.tensor(weight_data, true);
    
    println!("  Input tensor ID: {}", input_id);
    println!("  Weight tensor ID: {}", weight_id);
    
    // 3. –°–æ–∑–¥–∞–µ–º checkpoint –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏
    println!("\n2. Creating Checkpoint:");
    ctx.checkpoint(input_id)?;
    println!("  Checkpoint count after checkpointing: {}", ctx.checkpoint_count());
    
    // 4. –í—ã–ø–æ–ª–Ω—è–µ–º forward pass (–∏–º–∏—Ç–∞—Ü–∏—è)
    println!("\n3. Forward Pass Simulation:");
    
    // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã
    let input_tensor = ctx.get_tensor(input_id).unwrap();
    let weight_tensor = ctx.get_tensor(weight_id).unwrap();
    
    // –í—ã—á–∏—Å–ª—è–µ–º output = input @ weight.T
    let output = input_tensor.matmul(&weight_tensor.transpose(0, 1)?)?;
    let output_id = ctx.tensor(output, true);
    
    println!("  Output tensor ID: {}", output_id);
    println!("  Output shape: {:?}", ctx.get_tensor(output_id).unwrap().shape());
    
    // 5. –°–æ–∑–¥–∞–µ–º –µ—â–µ –æ–¥–∏–Ω checkpoint
    println!("\n4. Creating Second Checkpoint:");
    ctx.checkpoint(output_id)?;
    println!("  Checkpoint count: {}", ctx.checkpoint_count());
    
    // 6. –ò–º–∏—Ç–∏—Ä—É–µ–º backward pass —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º checkpoint
    println!("\n5. Backward Pass with Checkpoint Restoration:");
    
    // –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º checkpoint –¥–ª—è output
    let restored_output_id = ctx.restore_checkpoint(output_id, |ctx| {
        println!("    Recomputing forward pass from checkpoint...");
        
        // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –∑–∞–Ω–æ–≤–æ
        let input_tensor = ctx.get_tensor(input_id).unwrap();
        let weight_tensor = ctx.get_tensor(weight_id).unwrap();
        
        // –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º
        let output = input_tensor.matmul(&weight_tensor.transpose(0, 1)?)?;
        let output_id = ctx.tensor(output, true);
        
        Ok(output_id)
    })?;
    
    println!("  Restored output tensor ID: {}", restored_output_id);
    println!("  Checkpoint count after restoration: {}", ctx.checkpoint_count());
    
    // 7. –û—á–∏—â–∞–µ–º checkpoints
    println!("\n6. Cleaning Up:");
    ctx.clear_checkpoints();
    println!("  Checkpoint count after cleanup: {}", ctx.checkpoint_count());
    
    // 8. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –º–æ–¥—É–ª—è–º–∏
    println!("\n7. Individual Modules with Checkpointing:");
    
    let linear1 = Linear::<CpuTensor>::new(4, 8, &device)?;
    let relu = ReLU::<CpuTensor>::new(&device);
    let linear2 = Linear::<CpuTensor>::new(8, 3, &device)?;
    
    let test_input = CpuTensor::random_uniform(Shape::new(vec![1, 4]), -1.0, 1.0, &device)?;
    println!("  Test input shape: {:?}", test_input.shape());
    
    let output1 = linear1.forward(&test_input)?;
    let output2 = relu.forward(&output1)?;
    let output3 = linear2.forward(&output2)?;
    
    println!("  After linear1: {:?}", output1.shape());
    println!("  After relu: {:?}", output2.shape());
    println!("  Final output: {:?}", output3.shape());
    println!("  Final data: {:?}", output3.data());
    
    println!("\n‚úÖ Gradient checkpointing example completed successfully!");
    println!("   Memory-efficient training is now supported!");
    
    Ok(())
}
